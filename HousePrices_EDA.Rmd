---
title: "House Price EDA"
author: "Kazım Anıl Eren"
date: "9 Ocak 2018"
output: html_document
---

## Data Input
I have prepared the data in a separate R session and will make the future possible changes on that R script to prevent this RMd document getting messy.

```{r warning = FALSE, include = FALSE}
library(knitr)            # for knitting up.
library("easyGgplot2")    # for having multiple plots at once
library(psych)            # for Bartlett's test of sphericity
library("corrplot")       # for correlation plots
library("car")            # for Variance Inflation Factor
source("HousePrices_DataMunging.R")
```

## Notes

* It should be carefully noted that all p-values are rounded up to 5 digits.

## EDA via Graphs

### MSSubClass

```{r echo = FALSE}
ggplot(data = train, aes(x = MSSubClass, y = logSP, col = MSSubClass)) + 
  geom_boxplot() +
  theme_classic() + labs(x = "Classification", y = "Logarithm of Sale Price")
```

MSSubClass variable includes at least three dimensions of information. Thus i have divided it into three variables.

* Style
* PUD
* Story

#### Style Classification

```{r echo = FALSE}
ggplot(data = train, aes(x = Style, y = logSP, col = Style)) + 
  geom_boxplot() +
  theme_classic() + labs(x = "Style Classification", y = "Logarithm of Sale Price")
```

From the graph above, it is evident that New buildings are more expensive than the others. Still, let's check it with an ANOVA test. The p value is `r round(summary(aov(formula = logSP ~ New, data = train))[[1]][["Pr(>F)"]][1], digits = 5)` which is strong evidence. There are `r train[, .N, .(New)][New == 1]$N` new apartments, while `r train[, .N, .(New)][New == 0]$N` old and `r train[, .N, .(New)][is.na(New)]$N` otherwise.

```{r echo = FALSE}
ggplot(data = train, aes(x = New, y = logSP, col = New)) + 
  geom_boxplot() +
  theme_classic() + labs(x = "New Style or Not?", y = "Logarithm of Sale Price")
train[, Style := NULL]; test[, Style := NULL]
```

#### PUD or Not?
```{r echo = FALSE}
ggplot(data = train, aes(x = PUD, y = logSP, col = PUD)) + 
  geom_boxplot() +
  theme_classic() + labs(x = "Planned Unit Development", y = "Logarithm of Sale Price")
```

There seems there is not much difference between being a PUD or not. Let's confirm this via an ANOVA test. The p value is `r round(summary(aov(formula = logSP ~ PUD, data = train))[[1]][["Pr(>F)"]][1], digits = 5)` which depicts there is no correlation between prices and PUD.

#### Story Classification
```{r echo = FALSE}
ggplot(data = train, aes(x = Story, y = logSP, col = Story)) + 
  geom_boxplot() +
  theme_classic() + labs(x = "Story Classification", y = "Logarithm of Sale Price")
```

There seems reasonable difference between our story factors and ANOVA confirms this with a p value of `r round(summary(aov(formula = logSP ~ Story, data = train))[[1]][["Pr(>F)"]][1], digits = 5)`. The distribution of story values are as below:

```{r echo = FALSE}
kable(train[, .(Obs = .N), .(Story)][order(Story)], caption = "Story Distribution")
```

### MSZoning

Apartments are mostly located in RL (Residential - Low Density) zone as seen table below and the boxplot shows that MS Zoning is a candidate for regression. ANOVA confirms this output as well: `r round(summary(aov(formula = logSP ~ MSZoning, data = train))[[1]][["Pr(>F)"]][1], digits = 5)`

```{r echo = FALSE}
kable(train[, .(Obs = .N), .(MSZoning)][order(MSZoning)], caption = "MS Zoning Distribution", col.names = c("MS Zoning", "Amount of Observations"))
```

```{r echo = FALSE}
ggplot(data = train, aes(x = MSZoning, y = logSP, col = MSZoning)) + 
  geom_boxplot() +
  theme_classic() + labs(x = "Story Classification", y = "Logarithm of Sale Price")
```

### House Styling
```{r echo = FALSE}
ggplot(data = train, aes(x = BldgType, y = logSP, col = BldgType)) + 
  geom_boxplot() +
  theme_classic() + labs(x = "Building Type", y = "Logarithm of Sale Price")
```

```{r echo = FALSE}
ggplot(data = train, aes(x = Foundation, y = logSP, col = Foundation)) + 
  geom_boxplot() +
  theme_classic() + labs(x = "Foundation", y = "Logarithm of Sale Price")
```

```{r echo = FALSE}
ggplot(data = train, aes(x = HouseStyle, y = logSP, col = HouseStyle)) + 
  geom_boxplot() +
  theme_classic() + labs(x = "House Style", y = "Logarithm of Sale Price")
```

```{r echo = FALSE}
ggplot(data = train, aes(x = RoofMatl, y = logSP, col = RoofMatl)) + 
  geom_boxplot() +
  theme_classic() + labs(x = "Roof Material", y = "Logarithm of Sale Price")
train[, RoofMatl := NULL]; test[, RoofMatl := NULL]
```

```{r echo = FALSE}
ggplot(data = train, aes(x = RoofStyle, y = logSP, col = RoofStyle)) + 
  geom_boxplot() +
  theme_classic() + labs(x = "Roof Style", y = "Logarithm of Sale Price")
```

Even though all of them succeed in ANOVA tests, *Roof Material* could not succeed for the final phase of our analysis since the observations are concentrated in only one observation (namely **CompShg**). Also, *House Style* may have correlations with the variables created in MSSubClass section.
### Masonry Veneer

There is some dirty data (i.e. lines indicating **None** masonry with *some* masonry area) cleaned beforehand.

```{r echo = FALSE}
ggplot(data = train, aes(x = MasVnrType, y = logSP, col = MasVnrType)) + 
  geom_boxplot() + 
  theme_classic() + labs(x = "Masonry Veneer Type", y = "Logarithm of Sale Price")
```

Graph above presents, if there is a Masonry Veneer inside house then the price will go up depending on the type chosen. Graph below presents that if the area with masonry veneer increases than the price may go up as well.

```{r echo = FALSE}
ggplot(data = train[MasVnrArea > 0]) + 
        geom_jitter(aes(x = MasVnrArea, y = logSP, col = MasVnrArea)) + 
          geom_smooth(aes(x = MasVnrArea, y = logSP), col = "red", method = "lm") +
            theme_classic() + labs(x = "Masonry Veneer Area", y = "Logarithm of Sale Price")
train[is.na(MasVnrArea), MasVnrArea := 0]; test[is.na(MasVnrArea), MasVnrArea := 0]
```

### Land Features

*Land Contour* may keep some information about pricing of the houses as seen in the boxplot below:

```{r echo = FALSE}
ggplot(data = train, aes(x = LandContour, y = logSP, col = LandContour)) + 
  geom_boxplot() + 
  theme_classic() + labs(x = "Land Contour", y = "Logarithm of Sale Price")
```

Factors among *Land Slope* variable does not have significant difference in between as seen in the boxplot below and ANOVA p-value of `r round(summary(aov(formula = logSP ~ LandSlope, data = train))[[1]][["Pr(>F)"]][1], digits = 5)`.

```{r echo = FALSE}
ggplot(data = train, aes(x = LandSlope, y = logSP, col = LandSlope)) + 
  geom_boxplot() + 
  theme_classic() + labs(x = "Levels of Land Slope", y = "Logarithm of Sale Price")
train[, LandSlope := NULL]; test[, LandSlope := NULL]
```

### Neighborhood

An obvious connection with house prices is the house's neighborhood indeed. But during regressions, a reference point should be set among factors and determining the reference point is also important for inference. First of all let's see the distribution of the data via a boxplot and then set the reference level for the Neighborhood factor.

```{r echo = FALSE}
ggplot(data = train, aes(x = reorder(Neighborhood, logSP, median), y = logSP, col = Neighborhood)) + 
  geom_boxplot() + 
  theme_classic() + labs(x = "Neighborhood", y = "Logarithm of Sale Price")
```

For this factor, **"MeadowV"** neighborhood can be chosen as a reference level since it has the lowest median among all factors.

```{r echo = FALSE}
train[, Neighborhood := relevel(Neighborhood, ref = "MeadowV")]
```

### Access to Streets and Alleys

There are only `r train[!is.na(Alley), .N]` lines with Alley info meanwhile there are only `r train[Street == "Grvl", .N]` observations that have Gravel access to the streets. Thereby, I will skip these variables.

```{r echo = FALSE}
train[, ':='(Alley  = NULL, Street = NULL)]; 
test[, ':='(Alley  = NULL, Street = NULL)]
```

### Lot Features

When a histogram of LotArea is examined, it is seen that the distribution is much skewed. Thus the logarithm is taken. There is a significant (p-value of `r round(cor.test(train$logLotArea, train$logSP)[[3]], digits = 5)`) and somewhat strong (correlation co-efficient of `r cor.test(train$logLotArea, train$logSP)[[4]]`) relationship between logarithms of Sale Price and Lot Area as seen in the plot below.

```{r echo = FALSE}
train[, LotArea := NULL]; test[, LotArea := NULL]
ggplot(data = train, aes(x = logLotArea, y = logSP, col = logSP)) + 
  geom_jitter() + 
  theme_classic() + labs(x = "Logarithm of Lot Area", y = "Logarithm of Sale Price")
```

The same goes for Lot Frontage as well. However, there are **259 missing values to be handled**. The graph and correlation details are as below:

```{r echo = FALSE}
train[, LotFrontage := NULL]; test[, LotFrontage := NULL]
ggplot(data = train, aes(x = logLotFrontage, y = logSP, col = logSP)) + 
  geom_jitter() + 
  theme_classic() + labs(x = "Logarithm of Lot Frontage", y = "Logarithm of Sale Price")
train[, logLotFrontage := NULL]; test[, logLotFrontage := NULL]
```

```{r echo = FALSE}
cor.test(train$logLotFrontage, train$logSP)
```

For *Lot Shape* variable, there are not much observations in IR2 and IR3 Categories. Thereby, I have rearranged the data in the form of: Regular / Irregular. A boxplot will be presented for reference and ANOVA p-value is `r round(summary(aov(formula = logSP ~ LotShape, data = train))[[1]][["Pr(>F)"]][1], digits = 5)`

```{r echo = FALSE}
ggplot(data = train, aes(x = LotShape, y = logSP, col = LotShape)) + 
  geom_boxplot() + 
  theme_classic() + labs(x = "Lot Shape", y = "Logarithm of Sale Price")
```

For *Lot Config* variable, it seems that having a *"Cul-De-Sac Housing"* makes the difference if any. Thereby a Cul-De-Sac variable is created. Several AOV tests have suggested this outcome but i will skip those for simplicity.

```{r echo = FALSE}
ggplot(data = train, aes(x = CulDeSac, y = logSP, col = CulDeSac)) + 
  geom_boxplot() + 
  theme_classic() + labs(x = "Cul-De-Sac or Not?", y = "Logarithm of Sale Price")
```

### Info about Useable Area

```{r echo = FALSE}
cor_areas <- cor(train[, .(logSP, `1stFlrSF`, `2ndFlrSF`, LowQualFinSF, GrLivArea,
                           BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF,
                           TotalPorchSF, ScreenPorch, `3SsnPorch`, WoodDeckSF, EnclosedPorch, 
                           PoolArea, GarageArea)])
corrplot(cor_areas, type = "upper", sig.level = 0.05, insig = "blank")
rm(cor_areas)
```

A quick examination about Useable Areas depict that;

- **GrLivArea** can be used as an aggregate to **1stFlrSF**, **2ndFlrSF** and **LowQualFinSF**.
- **TotalBsmtSF** can be used as an aggregate to **BsmtFinSF1**, **BsmtFinSF2**, **BsmtUnfSF**.
- **TotalPorchSF** can be used as an aggregate to **ScreenPorch**, **3SsnPorch**, **WoodDeckSF**, **EnclosedPorch**, **OpenPorchSF**. However the last variable has a negative correlation with logSP thus a factor analysis will be conducted.
- **GarageArea** is a strong estimator and **PoolArea** can also be used.

```{r echo = FALSE}
pca_porch <- princomp(x = train[, .(ScreenPorch, `3SsnPorch`, WoodDeckSF, EnclosedPorch, OpenPorchSF)])
summary(pca_porch)
pca_porch$loadings
varimax(pca_porch$loadings)
rm(pca_porch)
```

New formula based on factor loadings:

```{r echo = FALSE}
train[, TotalPorchSF := (0.56933 * WoodDeckSF) + (0.16567 * OpenPorchSF) - (0.12876 * EnclosedPorch) + (0.10550 * ScreenPorch)]
test[,  TotalPorchSF := (0.56933 * WoodDeckSF) + (0.16567 * OpenPorchSF) - (0.12876 * EnclosedPorch) + (0.10550 * ScreenPorch)]
```

```{r echo = FALSE}
train[, ':='(`1stFlrSF` = NULL, `2ndFlrSF` = NULL, LowQualFinSF = NULL, 
             BsmtFinSF1 = NULL, BsmtFinSF2 = NULL, BsmtUnfSF = NULL,
             ScreenPorch = NULL, `3SsnPorch` = NULL, WoodDeckSF = NULL, EnclosedPorch = NULL, OpenPorchSF = NULL)]
test[, ':='(`1stFlrSF` = NULL, `2ndFlrSF` = NULL, LowQualFinSF = NULL, 
            BsmtFinSF1 = NULL, BsmtFinSF2 = NULL, BsmtUnfSF = NULL,
            ScreenPorch = NULL, `3SsnPorch` = NULL, WoodDeckSF = NULL, EnclosedPorch = NULL, OpenPorchSF = NULL)]
```

### Bath Features

Let's check with *Bartlett's test of Sphericity* if we can utilize **PCA** on this dataset.

```{r echo = FALSE}
bath_cor <- cor(train[, .(BsmtFullBath, BsmtHalfBath, FullBath, HalfBath)])
cortest.bartlett(bath_cor, n = nrow(train))
rm(bath_cor)
```

```{r echo = FALSE}
bath_pca <- prcomp(train[, .(BsmtFullBath, BsmtHalfBath, FullBath, HalfBath)])
```

A principal component analysis shows that there are no correlation between these four arguments while assigning more weight *FullBaths* over *HalfBaths* and *Above Grade Baths* over *Basement Baths*. Also, since the factors are pure there is no need for a **Varimax rotation**.

```{r echo = FALSE}
train[, Bath := (0.374 * FullBath) + (0.300 * BsmtFullBath) + (0.264 * HalfBath) + (0.0624 * BsmtHalfBath)]
train[, ':='(FullBath = NULL, HalfBath = NULL, BsmtFullBath = NULL, BsmtHalfBath = NULL)]
test[is.na(BsmtFullBath), BsmtFullBath := 0]
test[is.na(BsmtHalfBath), BsmtHalfBath := 0]
test[, Bath := (0.374 * FullBath) + (0.300 * BsmtFullBath) + (0.264 * HalfBath) + (0.0624 * BsmtHalfBath)]
test[, ':='(FullBath = NULL, HalfBath = NULL, BsmtFullBath = NULL, BsmtHalfBath = NULL)]
rm(bath_pca)
```

### Living Space / Rooms Features

```{r echo = FALSE}
cor_rooms <- cor(train[, .(logSP, BedroomAbvGr, KitchenAbvGr, TotRmsAbvGrd, OneKitchen)])
corrplot(cor_rooms, type = "upper", sig.level = 0.05, insig = "blank", method = "number")
rm(cor_rooms)
train[, ':='(KitchenAbvGr = NULL, TotRmsAbvGrd = NULL)]; test[, ':='(KitchenAbvGr = NULL, TotRmsAbvGrd = NULL)]
```

Having more than one kitchen decreases the price thereby **OneKitchen** variable is created and TotRmsAbvGrd will not be used since there are two forces in opposite direction within.

### Basement Features

ANOVA tests below suggests that, we should use *Basement Exposure* and a dummy called *Good Finished Basement* (BsmtFinType1 == "GLQ").

```{r echo = FALSE}
ggplot(data = train, aes(x = BsmtExposure, y = logSP, col = BsmtExposure)) + 
  geom_boxplot() + 
  theme_classic() + labs(x = "Basement Exposure", y = "Logarithm of Sale Price")
train[is.na(BsmtExposure), BsmtExposure := "NoBasement"]; test[is.na(BsmtExposure), BsmtExposure := "NoBasement"]
train[, BsmtExposure := relevel(BsmtExposure, "NoBasement")]; test[, BsmtExposure := relevel(BsmtExposure, "NoBasement")]
```

```{r echo = FALSE}
ggplot(data = train, aes(x = BsmtFinType1, y = logSP, col = BsmtFinType1)) + 
  geom_boxplot() + 
  theme_classic() + labs(x = "Finished Basement 1 Type", y = "Logarithm of Sale Price")
train[is.na(BsmtFinType1), BsmtFinType1 := "NoBasement"]; test[is.na(BsmtFinType1), BsmtFinType1 := "NoBasement"]
train[, GoodFinBsmt := ifelse(BsmtFinType1 == "GLQ", 1, 0)]; test[, GoodFinBsmt := ifelse(BsmtFinType1 == "GLQ", 1, 0)]
```

```{r echo = FALSE}
summary(aov(logSP ~ BsmtExposure, train))
```

```{r echo = FALSE}
summary(aov(logSP ~ BsmtFinType1, train))
```

```{r echo = FALSE}
summary(aov(logSP ~ BsmtFinType1 == "GLQ", train))
```

```{r echo = FALSE}
summary(aov(logSP ~ BsmtFinType2, train))
train[, ':='(BsmtFinType1 = NULL, BsmtFinType2 = NULL)]; test[, ':='(BsmtFinType1 = NULL, BsmtFinType2 = NULL)]
```

### Garage Features

As will be seen in the correlation-graph below, *Garage Area* and *Garage Cars* have similar levels of relation with logarithm of sale price but since *Garage Area* is numeric, we will go with it.

```{r echo = FALSE}
cor_grg <- cor(train[, .(logSP, GarageArea, GarageCars)])
corrplot(cor_grg, type = "upper", sig.level = 0.05, insig = "blank", method = "number")
rm(cor_grg)
train[is.na(GarageArea), GarageArea := 0]; test[is.na(GarageArea), GarageArea := 0]
train[, GarageCars := NULL]; test[, GarageCars := NULL]
```

The next two boxplots indicate that *Garage Finish* and *Garage Type* could be estimators of house pricing. However, before approaching to the analysis step we must take care of NA values and convert them into a factor called "NoGarage".

```{r echo = FALSE}
ggplot(data = train, aes(x = GarageFinish, y = logSP, col = GarageFinish)) + 
  geom_boxplot() + 
  theme_classic() + labs(x = "Garage Finish", y = "Logarithm of Sale Price")
train[is.na(GarageFinish), GarageFinish := "NoGarage"]; test[is.na(GarageFinish), GarageFinish := "NoGarage"]
train[, GarageFinish := relevel(GarageFinish, "NoGarage")]; test[, GarageFinish := relevel(GarageFinish, "NoGarage")]
```

```{r echo = FALSE}
ggplot(data = train, aes(x = GarageType, y = logSP, col = GarageType)) + 
  geom_boxplot() + 
  theme_classic() + labs(x = "Garage Type", y = "Logarithm of Sale Price")
train[is.na(GarageType), GarageType := "NoGarage"]; test[is.na(GarageType), GarageType := "NoGarage"]
train[, GarageType := relevel(GarageType, "NoGarage")]; test[, GarageType := relevel(GarageType, "NoGarage")]
```

### Heating, Fireplace & Utilities

```{r echo = FALSE}
train[, .N, .(Heating)][order(-N)]
train[, Heating := as.factor(ifelse(Heating == "GasA", "Standard", "NonStandard"))]; train[is.na(Heating), Heating := "NonStandard"]
test[,  Heating := as.factor(ifelse(Heating == "GasA", "Standard", "NonStandard"))]; test[is.na(Heating), Heating := "NonStandard"]
train[, Heating := relevel(Heating, "NonStandard")]; test[, Heating := relevel(Heating, "NonStandard")]
```

```{r echo = FALSE}
train[, .N, .(Electrical)][order(-N)]
train[, Electrical := as.factor(ifelse(Electrical == "SBrkr", "Standard", "NonStandard"))]; train[is.na(Electrical), Electrical := "NonStandard"]
test[,  Electrical := as.factor(ifelse(Electrical == "SBrkr", "Standard", "NonStandard"))]; test[is.na(Electrical), Electrical := "NonStandard"]
train[, Electrical := relevel(Electrical, "NonStandard")]; test[, Electrical := relevel(Electrical, "NonStandard")]
```

Since observations in **Heating** variable is concentrated on "GasA". We will label "GasA" as *Standard* and others as *NonStandard*. Same goes for "SBrkr" observation of **Electrical** variable. Let's depict the differences in prices of *Standard* and *Non-Standard* equipment.

```{r echo = FALSE}
p1 <- ggplot(data = train) + 
        geom_boxplot(aes(x = Heating, y = logSP, col = Heating)) + 
          theme_classic() + labs(x = "Heating", y = "Logarithm of Sale Price")
p2 <- ggplot(data = train) + 
        geom_boxplot(aes(x = Electrical, y = logSP, col = Electrical)) + 
          theme_classic() + labs(x = "Electrical", y = "Logarithm of Sale Price")
ggplot2.multiplot(p1, p2); rm(p1,p2)
```

Next graphic visualizes the availability of fireplaces and central air equipments in the houses and they both seem to affect the prices as well!

```{r echo = FALSE}
train[, CentralAir := as.factor(ifelse(CentralAir == "Y", "Yes", "No"))]
test[,  CentralAir := as.factor(ifelse(CentralAir == "Y", "Yes", "No"))]
train[, CentralAir := relevel(CentralAir, "No")] 
test[,  CentralAir := relevel(CentralAir, "No")]

train[, Fireplaces := as.factor(ifelse(Fireplaces > 0, "Exist", "None"))]
test[,  Fireplaces := as.factor(ifelse(Fireplaces > 0, "Exist", "None"))]
train[, Fireplaces := relevel(Fireplaces, "None")]
test[,  Fireplaces := relevel(Fireplaces, "None")]

p1 <- ggplot(data = train, aes(x = CentralAir, y = logSP, col = CentralAir)) + 
        geom_boxplot() +
          theme_classic() + labs(x = "Central Air Equipment", y = "Logarithm of Sale Price")
p2 <- ggplot(data = train, aes(x = Fireplaces, y = logSP, col = Fireplaces)) + 
        geom_boxplot() +
          theme_classic() + labs(x = "Any fireplace?", y = "Logarithm of Sale Price")
ggplot2.multiplot(p1, p2); rm(p1,p2)
```

### Timing of Sale

A simple AOV depicts that there are no significant difference in *log - sale prices* among sale months.

```{r echo = FALSE}
summary(aov(logSP ~ as.factor(MoSold), train))
```

Even for separating the months with Low/High sale frequencies do not change the outcome (Months between March and August, both exclusive are chosen as frequent-sale months):

```{r echo = FALSE}
summary(aov(logSP ~ (MoSold > 3 & MoSold < 8), train))
```

Same goes for Sale Year. No correlation with the prices and no significant bust or booms across years.

```{r echo = FALSE}
summary(aov(logSP ~ as.factor(YrSold), train))
```

```{r echo = FALSE}
cor.test(train$logSP, train$YrSold)
```

On the other there may be correlation among sale-date and log-mean sale prices.

```{r echo = FALSE}
acf(train[, .(LogMeanSalePrice = log10(mean(SalePrice))), .(Time = as.Date(paste0(YrSold, "-", MoSold, "-01")))][order(Time)][, 2])
```

It seems that there is a negative relationship with lagged (4m) log-mean prices yet the graph below shows that could be some white noise as well. Thus we will omit time variables in this research.

```{r echo = FALSE}
monthly_lmsp <- train[, .(LogMeanSalePrice = log10(mean(SalePrice))), .(Time = as.Date(paste0(YrSold, "-", MoSold, "-01")))]
ggplot(data = monthly_lmsp[order(Time)][1:54],
       aes(x = Time, y = LogMeanSalePrice)) + geom_line() + geom_smooth() +
  theme_classic() + labs(x = "Time", y = "Logarithm of Monthly Mean Sale Price")
```

```{r echo = FALSE}
train[, MoSold := NULL]; test[, MoSold := NULL]
train[, YrSold := NULL]; test[, YrSold := NULL]
rm(monthly_lmsp)
```

### Age

We had two assumptions while calculating the ages of the buildings:

- All buildings are built at the first day of the year.
- *Today* is the first day of 2011. (The data ends at July, 2010)

First of all let's plot the variables on jitter & smooth (loess) graphs. 

```{r echo = FALSE}
p1 <- ggplot(data = train[HouseAge < 90]) + 
        geom_jitter(aes(x = HouseAge, y = logSP, col = HouseAge)) + 
          geom_smooth(aes(x = HouseAge, y = logSP), col = "red", method = "loess") +
            theme_classic() + labs(x = "House Age", y = "Logarithm of Sale Price")
p2 <- ggplot(data = train[RemodeledAge < 60]) + 
        geom_jitter(aes(x = RemodeledAge, y = logSP, col = RemodeledAge)) + 
          geom_smooth(aes(x = RemodeledAge, y = logSP), col = "red", method = "loess") +
            theme_classic() + labs(x = "Years Past Remodelling", y = "Logarithm of Sale Price")
p3 <- ggplot(data = train[GarageAge < 90]) + 
        geom_jitter(aes(x = GarageAge, y = logSP, col = GarageAge)) + 
          geom_smooth(aes(x = GarageAge, y = logSP), col = "red", method = "loess") +
            theme_classic() + labs(x = "Garage Age", y = "Logarithm of Sale Price")
ggplot2.multiplot(p1, p2, p3, cols = 3); rm(p1, p2, p3)
```

Since a possible 2nd degree effect is possible let's check the CorrPlot of these variables and their 2nd degrees with log-saleprice. 

```{r echo = FALSE}
corm_ages <- cor(train[, .(logSP, 
                           HouseAge, HouseAge2 = HouseAge^2, 
                           RemodeledAge, RemodeledAge2 = RemodeledAge^2, 
                           GarageAge, GarageAge2 = GarageAge^2)],
                 use = "complete.obs")
corrplot(corm_ages, type = "upper", sig.level = 0.05, insig = "blank")
rm(corm_ages)
```

Possible 2nd degree effects are confirmed. On the other hand, those values have high correlations among themselves as well. Thereby, using them together could pose a problem. We may choose the best performing variable amongst by looking up the AIC of simple linear regressions.

```{r echo = FALSE}
kable(cbind(Variables  = c("HouseAge", "GarageAge", "RemodeledAge"),
            AIC_Scores = c(round(AIC(lm(logSP ~ HouseAge + HouseAge2, train)), digits = 2),
                           round(AIC(lm(logSP ~ GarageAge + GarageAge2, train)), digits = 2),
                           round(AIC(lm(logSP ~ RemodeledAge + RemodeledAge2, train)), digits = 2))),
      col.names = c("Age Variables", "Akaike Information Criteria"))
test[, ':='(HouseAge = NULL, HouseAge2 = NULL,  GarageAge = NULL, GarageAge2 = NULL)] 
train[, ':='(HouseAge = NULL, HouseAge2 = NULL,  GarageAge = NULL, GarageAge2 = NULL)] 
```

Remodeled Age and its 2nd degree variable will be used.


### Condition & Quality Features

First of all let's have a look at overall quality and condition distributions and their relationship with **logarith of Sale Price**.

```{r echo = FALSE}
merge(train[, .(OverallCondition = .N) , .(Rating = OverallCond)],
      train[, .(OverallQuality = .N) , .(Rating = OverallQual)],
      all.y = T, by = "Rating")
```

```{r echo = FALSE}
p1 <- ggplot(data = train) + 
        geom_boxplot(aes(x = as.factor(OverallCond), y = logSP, col = OverallCond)) + 
          theme_classic() + labs(x = "Overall Condition", y = "Logarithm of Sale Price")
p2 <- ggplot(data = train) + 
        geom_boxplot(aes(x = as.factor(OverallQual), y = logSP, col = OverallQual)) + 
          theme_classic() + labs(x = "Overall Quality", y = "Logarithm of Sale Price")
ggplot2.multiplot(p1, p2); rm(p1,p2)
train[, OverallCond := NULL]; test[, OverallCond := NULL]
```

It seems that *Overall Quality* could be a possible explanatory variable. The correlation with *logSP* is also significant and high (`r cor(train$OverallQual, train$logSP)`).

For the rest of the Quality and Condition indicators (except *Functional* and *Fence* variables) a numeric transformation is made. i.e. NA 0, Poor 1 and upto 5 as Excellent in given order. Then let's examine the variables one by one.

```{r echo = FALSE}
source("Quality.R")
train[, ':='(BsmtQual = quality(BsmtQual),
             ExterQual = quality(ExterQual),
             GarageQual = quality(GarageQual),
             KitchenQual = quality(KitchenQual),
             HeatingQC = quality(HeatingQC),
             FireplaceQu = quality(FireplaceQu),
             PoolQC = quality(PoolQC),
             BsmtCond = quality(BsmtCond),
             ExterCond = quality(ExterCond),
             GarageCond = quality(GarageCond))]
```

```{r echo = FALSE}
ggplot(data = train) + 
  geom_boxplot(aes(x = as.factor(BsmtQual), y = logSP, col = BsmtQual)) +
    theme_classic() + labs(x = "Basement Quality", y = "Logarithm of Sale Price")
```

```{r echo = FALSE}
ggplot(data = train) +
  geom_boxplot(aes(x = as.factor(ExterQual), y = logSP, col = ExterQual)) +
    theme_classic() + labs(x = "External Quality", y = "Logarithm of Sale Price")
```

```{r echo = FALSE}
ggplot(data = train) +
  geom_boxplot(aes(x = as.factor(GarageQual), y = logSP, col = GarageQual)) +
    theme_classic() + labs(x = "Garage Quality", y = "Logarithm of Sale Price")
```

```{r echo = FALSE}
kable(train[, .N, .(GarageQual)], col.names = c("Garage Quality", "Amount of Observations"))
```

```{r echo = FALSE}
ggplot(data = train) +
  geom_boxplot(aes(x = as.factor(KitchenQual), y = logSP, col = KitchenQual)) +
    theme_classic() + labs(x = "Kitchen Quality", y = "Logarithm of Sale Price")
```

```{r echo = FALSE}
ggplot(data = train) +
  geom_boxplot(aes(x = as.factor(HeatingQC), y = logSP, col = HeatingQC)) +
    theme_classic() + labs(x = "Heating Quality", y = "Logarithm of Sale Price")
```

```{r echo = FALSE}
ggplot(data = train) +
  geom_boxplot(aes(x = as.factor(FireplaceQu), y = logSP, col = FireplaceQu)) +
    theme_classic() + labs(x = "Fireplace Quality", y = "Logarithm of Sale Price")
```

```{r echo = FALSE}
kable(train[, .N, .(FireplaceQu)], col.names = c("Fireplace Quality", "Amount of Observations"))
```

```{r echo = FALSE}
ggplot(data = train) +
  geom_boxplot(aes(x = as.factor(PoolQC), y = logSP, col = PoolQC)) +
    theme_classic() + labs(x = "Pool Quality", y = "Logarithm of Sale Price")
```

```{r echo = FALSE}
ggplot(data = train) +
  geom_boxplot(aes(x = as.factor(BsmtCond), y = logSP, col = BsmtCond)) +
    theme_classic() + labs(x = "Basement Condition", y = "Logarithm of Sale Price")
```

```{r echo = FALSE}
kable(train[, .N, .(BsmtCond)], col.names = c("Basement Condition", "Amount of Observations"))
```

```{r echo = FALSE}
ggplot(data = train) +
  geom_boxplot(aes(x = as.factor(ExterCond), y = logSP, col = ExterCond)) +
    theme_classic() + labs(x = "Exterior Conditions", y = "Logarithm of Sale Price")
```

```{r echo = FALSE}
kable(train[, .N, .(ExterCond)], col.names = c("Exterior Condition", "Amount of Observations"))
```

```{r echo = FALSE}
ggplot(data = train) +
  geom_boxplot(aes(x = as.factor(GarageCond), y = logSP, col = GarageCond)) +
    theme_classic() + labs(x = "Garage Condition", y = "Logarithm of Sale Price")
```

```{r echo = FALSE}
kable(train[, .N, .(GarageCond)], col.names = c("Garage Condition", "Amount of Observations"))
```

```{r echo = FALSE}
ggplot(data = train) +
  geom_boxplot(aes(x = Functional, y = logSP, col = Functional)) +
    theme_classic() + labs(x = "Functionality", y = "Logarithm of Sale Price")
```

```{r echo = FALSE}
kable(train[, .N, .(Functional)], col.names = c("Functionality", "Amount of Observations"))
```

```{r echo = FALSE}
ggplot(data = train) +
  geom_boxplot(aes(x = Fence, y = logSP, col = Fence)) +
    theme_classic() + labs(x = "Fence", y = "Logarithm of Sale Price")
```

```{r echo = FALSE}
kable(train[, .N, .(Fence)], col.names = c("Fence", "Amount of Observations"))
```

- *Basement Quality*, *Exterior Quality*, *Heating Quality* and *Kitchen Quality* variables do seem to have a relationship with logarithm of sale-prices while;
- *Basement Condition*, *Exterior Condition*, *Fence*, *Fireplace Quality*, *Functionality*, *Garage Condition* and *Garage Quality* does not seem to have a relationship with the logarithm of sale-prices. 
- Now, let's check for the possible correlations among the selected variables;

```{r echo = FALSE}
cor_cq <- cor(train[, .(logSP, OverallQual, BsmtQual, ExterQual, HeatingQC, KitchenQual)])
corrplot(cor_cq, type = "upper", sig.level = 0.05, insig = "blank", method = "number")
rm(cor_cq)
```

It seems that *Overall Quality* has the highest correlation with logarithm of Sale-Prices and maintain a good correlation with other variables as well. Thus, Only *Overall Quality* will be used in the analysis to prevent **multi co-linearity issues*.

```{r}
train[, ':='(BsmtQual = NULL, ExterQual = NULL, GarageQual = NULL, KitchenQual = NULL, HeatingQC = NULL, FireplaceQu = NULL, PoolQC = NULL, 
             BsmtCond = NULL, ExterCond = NULL, GarageCond = NULL, Functional = NULL, Fence = NULL)]
test[, ':='(BsmtQual = NULL, ExterQual = NULL, GarageQual = NULL, KitchenQual = NULL, HeatingQC = NULL, FireplaceQu = NULL, PoolQC = NULL, 
             BsmtCond = NULL, ExterCond = NULL, GarageCond = NULL, Functional = NULL, Fence = NULL)]
```

#### Sale Agreement

```{r echo = FALSE}
p1 <- ggplot(data = train) + 
        geom_boxplot(aes(x = SaleType, y = logSP, col = SaleType)) + 
          theme_classic() + labs(x = "Sale Type", y = "Logarithm of Sale Price")
p2 <- ggplot(data = train) + 
       geom_boxplot(aes(x = SaleCondition, y = logSP, col = SaleCondition)) + 
         theme_classic() + labs(x = "Sale Condition", y = "Logarithm of Sale Price")
ggplot2.multiplot(p1, p2); rm(p1,p2)
```

Examining these two plots indicate that the main difference in prices may come from the sale of a New (Type) / Partial (Condition) house. Let's have a look:

```{r echo = FALSE}
train[, NewBuilding := ifelse(SaleType == "New" | SaleCondition == "Partial", "New", "Not New")]
test[, NewBuilding := ifelse(SaleType == "New" | SaleCondition == "Partial", "New", "Not New")]
test[is.na(SaleType), NewBuilding := "Not New"]
train[, NewBuilding := relevel(as.factor(NewBuilding), "Not New")]; test[, NewBuilding := relevel(as.factor(NewBuilding), "Not New")]
summary(aov(logSP ~ NewBuilding, train))
```

```{r echo = FALSE}
ggplot(data = train) + 
       geom_boxplot(aes(x = NewBuilding, y = logSP, col = NewBuilding)) + 
         theme_classic() + labs(x = "Sale of a New Building or Not", y = "Logarithm of Sale Price")
```

#### Proximity & PavedDrive

Condition1 & Condition2 are grouped in four clusters based on their specifications. Next graph depicts how **PavedDrive** and **Proximity**

* *Main* as being close to the Artery or Feeder streets.
* *Positive* as being close to the Positive attractions.
* *Railroad* as being close to Railroad services.
* *Norm* as no specialty.

```{r echo = FALSE}
p1 <- ggplot(data = train) + 
        geom_boxplot(aes(x = Proximity, y = logSP, col = Proximity)) + 
          theme_classic() + labs(x = "Proximity Clusters", y = "Logarithm of Sale Price")
p2 <- ggplot(data = train) + 
       geom_boxplot(aes(x = PavedDrive, y = logSP, col = PavedDrive)) + 
         theme_classic() + labs(x = "PavedDrive", y = "Logarithm of Sale Price")
ggplot2.multiplot(p1, p2); rm(p1,p2)
```

### Miscellaneous Features

```{r echo = FALSE}
merge(train[, .(Train = .N), .(MiscFeature)],
      test[, .(Test = .N), .(MiscFeature)],
      all.x = T, by = "MiscFeature")
train[, MiscFeature := NULL]; test[, MiscFeature := NULL]
```

It seems that observations for *Miscellaneous Features* are not enough and AOV does not approve so (p-value is `r round(summary(aov(logSP ~ MiscFeature, train))[[1]][["Pr(>F)"]][1], digits = 5)`) yet their values (*MiscVal*) will be employed during the final calculations. (i.e. logSP is calculating with a deduction of MiscVal of SalePrice)

### The End of EDA
```{r echo = FALSE}
rm(quality)
save(test, train, file = "HousePrices_AfterEDA.RData")
```

